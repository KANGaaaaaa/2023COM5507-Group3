{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14867663-cf17-48d2-a56d-9f7cab46efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "# Load the provided Excel file\n",
    "file_path_bbc_csv = 'C:/Users/75800/Desktop/COM5507/1212/csv/NYT clean.csv'\n",
    "df_bbc_csv = pd.read_csv(file_path_bbc_csv)\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "df_bbc_csv.head()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Applying TF-IDF Vectorization without language filtering\n",
    "tfidf_vectorizer_no_lang_filter = TfidfVectorizer(stop_words='english', max_df=0.7, min_df=10)\n",
    "X_tfidf_no_lang_filter = tfidf_vectorizer_no_lang_filter.fit_transform(df_bbc_csv['Comment'].dropna().astype(str))\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Applying LSA (Truncated SVD) for topic modeling without language filtering\n",
    "lsa_no_lang_filter = TruncatedSVD(n_components=5, random_state=0)\n",
    "lsa_no_lang_filter.fit(X_tfidf_no_lang_filter)\n",
    "\n",
    "# Function to display the top words in each topic\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "# Displaying the top words in each topic without language filtering\n",
    "no_top_words = 10\n",
    "display_topics(lsa_no_lang_filter, tfidf_vectorizer_no_lang_filter.get_feature_names_out(), no_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9a273129-2558-4bd2-92c1-b13d938bc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the results of LSA topic modeling analysis in a DataFrame for output\n",
    "\n",
    "# Extracting the top words for each topic\n",
    "topics = []\n",
    "for i, topic in enumerate(lsa_no_lang_filter.components_):\n",
    "    topic_terms = [tfidf_vectorizer_no_lang_filter.get_feature_names_out()[index] for index in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    topics.append(\" \".join(topic_terms))\n",
    "\n",
    "# Creating a DataFrame to store the topics\n",
    "topics_df = pd.DataFrame(topics, columns=[\"Topic Words\"], index=[f\"Topic {i+1}\" for i in range(len(topics))])\n",
    "\n",
    "# Displaying the DataFrame\n",
    "topics_df\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "output_file_path = 'C:/Users/75800/Desktop/COM5507/1212/topic model/NYT topic model.csv'\n",
    "topics_df.to_csv(output_file_path, index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64541b05-6785-41a3-88ec-6f3fdfc2a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the results of LSA topic modeling analysis in a DataFrame for output\n",
    "\n",
    "# Extracting the top words for each topic\n",
    "topics = []\n",
    "for i, topic in enumerate(lsa_no_lang_filter.components_):\n",
    "    topic_terms = [tfidf_vectorizer_no_lang_filter.get_feature_names_out()[index] for index in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    topics.append(\" \".join(topic_terms))\n",
    "\n",
    "# Creating a DataFrame to store the topics\n",
    "topics_df = pd.DataFrame(topics, columns=[\"Topic Words\"], index=[f\"Topic {i+1}\" for i in range(len(topics))])\n",
    "\n",
    "# Displaying the DataFrame\n",
    "topics_df\n",
    "\n",
    "# Saving the DataFrame to a CSV file\n",
    "output_file_path = 'C:/Users/75800/Desktop/COM5507/1212/topic model/NYT topic model.csv'\n",
    "topics_df.to_csv(output_file_path, index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c220ea1b-7915-48ea-8a31-49d286a8705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # Import seaborn for more color options\n",
    "\n",
    "# Saving the visualization to a file\n",
    "\n",
    "# Set the file path for the output image\n",
    "output_image_path = '/Users/75800/Desktop/COM5507/1212/topic model/NYT topic model.png'\n",
    "\n",
    "# Number of topics and words\n",
    "n_components = 5  # Replace with the number of topics you have\n",
    "num_words = 10    # Number of top words to display in each topic\n",
    "\n",
    "# Recreating the subplots for each topic in a horizontal layout\n",
    "fig, axes = plt.subplots(1, n_components, figsize=(15, 10))\n",
    "fig.tight_layout(pad=6.0)\n",
    "\n",
    "# Define a color palette\n",
    "palette = sns.color_palette(\"husl\", n_components)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    # Sorting the components by weight and getting the top words\n",
    "    components = lsa_no_lang_filter.components_[i]\n",
    "    top_indices = components.argsort()[-num_words:][::-1]\n",
    "    top_values = components[top_indices]\n",
    "    top_words = [tfidf_vectorizer_no_lang_filter.get_feature_names_out()[j] for j in top_indices]\n",
    "\n",
    "    # Creating a bar plot for each topic with different colors\n",
    "    ax.barh(top_words, top_values, color=palette[i])\n",
    "    ax.set_title(f'Topic {i+1}')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(output_image_path)\n",
    "\n",
    "# Provide the path for downloading\n",
    "output_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1ea983-dd1a-43d6-b4b0-489581c2f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "n_components = 5 \n",
    "num_words = 10  \n",
    "\n",
    "# DataFrame to store the distribution of top words across topics\n",
    "word_distribution = pd.DataFrame()\n",
    "\n",
    "for i in range(n_components):\n",
    "    top_indices = lsa_no_lang_filter.components_[i].argsort()[-num_words:][::-1]\n",
    "    for j in top_indices:\n",
    "        word = tfidf_vectorizer_no_lang_filter.get_feature_names_out()[j]\n",
    "        word_distribution.at[word, f'Topic {i+1}'] = lsa_no_lang_filter.components_[i][j]\n",
    "\n",
    "# Normalizing the distribution\n",
    "word_distribution = word_distribution.div(word_distribution.max(axis=1), axis=0)\n",
    "\n",
    "# Plotting the distribution\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(word_distribution, annot=True, cmap='YlGnBu')\n",
    "plt.title(\"Word Distribution Across Topics\")\n",
    "plt.ylabel(\"Words\")\n",
    "plt.xlabel(\"Topics\")\n",
    "\n",
    "# Save the heatmap to a file before calling plt.show()\n",
    "output_path = '/Users/75800/Desktop/COM5507/1212/heat map/NYT topic heat map.png'\n",
    "plt.savefig(output_path)\n",
    "\n",
    "# Now show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
